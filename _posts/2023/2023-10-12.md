---
layout:     post
title:      "千万级订单场景下的架构稳定性，单元化建设方案"
subtitle:   "架构 稳定性 单花化"
author:     "Ace Mei"
categories:  架构
---

# 背景

随着公司业务体量的发展，业务领来了一个快速发展期，此时面临的核心挑战

- 随着公司产品的品牌的影响力约来越大，业务的体量越来越大， 对系统的稳定性，可用性
  也提出了更高的要求。
  （稳定性）
- 快速的产品运营和营销活动，对产品的快速适应和迭代带来挑战。
   技术中心需要满足，产品快速迭代带来的新增业务需求，满足公司的快速发展需要。
   此时技术开发的效率 是一个核心突破点
  （效率）
- 为了能满足即将到来的千万级，上亿级的订单压力，对当前系统架构的性能提升
  （单元化）

# 目标

  从卓越架构的视角出发，分析考虑应对如上挑战，架构在稳定性和高性能方面的建设方案

# 竞品方案调研

## 稳定性

   一个稳定的分布式系统需要能够快速适应变化，及时发现和解决问题，并且能够保持系统的一致性和可靠性。稳定性通常包含系统可用性、可靠性、可观测性、可运维性、可扩展性、可维护性等。
   云计算平台服务可以更好的构建系统稳定性，例如云计算平台可以根据系统的实际需求，动态分配和释放计算资源，使得系统更容易扩展，降低系统负载压力，从而提高系统的可扩展性。再者云计算平台会提供冗余存储和备份能力，避免系统因为硬件故障或其他原因导致的停机或数据丢失。这种备份机制可以提高系统的可靠性。

### 设计原则
在分布式系统中，需要考虑的稳定性问题比较复杂，贯穿软件系统设计态、研发态、运维态、运行态，覆盖从IaaS、PaaS到上层SaaS系统，所有这些都可能会影响系统的稳定性。为了确保系统能够持续稳定地工作，建议遵循以下设计原则。


#### 面向失败的架构设计原则
众所周知，系统异常事件是不可避免的，如网络延迟、硬件故障、软件错误、突峰流量等，建议在系统设计阶段就要从这些异常事件引起的系统执行“失败”出发，提供冗余、隔离、降级、弹性等能力，旨在确保系统的高可用性和高可靠性，以应对不可避免的故障和意外发生。



#### 面向精细的运维管控原则

由于业务的扩展和系统服务进一步拆分，分布式系统的复杂度剧增。再加上产品迭代加快，版本繁多，同时某些业务对实时性有较高要求，运维的不确定性和复杂性大幅增加。建议通过精细化的管理和可观测手段，如
- 版本控制、
- 灰度发布、
- 监控告警、
- 自动巡检等手段，
旨在提高运维效率、确定性和稳定性。


#### 面向风险的应急快恢原则

在一些场景下，即使设计了各种技术手段去提高系统的冗余、保持业务的高可用，但还是避免不了生产系统故障的发生，所以需要面对故障建立一个高效的故障应急流程机制和稳定的技术平台，实现故障风险实时发现、应急团队有效协同、处理过程准确记录、故障快速止损和恢复以及后续故障复盘，旨在提高故障应急效率，减小故障影响，降低类似故障的再次发生，提升系统整体高可用性。


# 设计方案
基于稳定性支柱设计原则，整体稳定性设计方案可参考如下：
![](https://ieasydevops.github.io/assets/images/2023/1012/stability_architecture.png)


## 架构设计原则

软件系统从所有的功能都在一个应用程序内运行的单体应用架构，到不同的功能模块分别部署在不同的服务器上的传统分布式应用架构，再到服务细分通过轻量级的通信机制进行互相调用的微服务架构，到现在将云计算、容器化、微服务架构等技术结合起来的云原生架构。在软件系统架构演进中不变的是系统的基本属性，包含存储、计算和网络，变的是存储、计算和网络的实现方式和规模，往大规模、高性能、高可靠、易扩展等方向迭代演进，所以对架构稳定性提出了更高的要求。

系统可预见的稳定性风险包含软硬件故障和不可预期的流量，小到线程级风险，大到地域级灾难，从此出发可通过容灾、容错、容量三方面建立系统架构稳定性。

### 容灾

容灾就是在灾难发生时，在保证生产系统的数据尽量少丢失的情况下，保持生存系统的业务不间断地运行。
异地多活、同城双活都属于容灾的范畴。
借助云服务多区域（Region）及可用区（Availability Zone，简称AZ）能力，应用可以用较小成本来完成容灾架构部署。

容灾需要具备较为完善的数据保护与灾难恢复功能，保证生产中心不能正常工作时数据的完整性及业务的连续性，并在最短时间内由灾备中心接替，恢复业务系统的正常运行，将损失降到最小。

### 容错

容错是指在分布式系统中，系统出现故障时，通过设计和实现可靠的机制和策略，使系统能够自动检测、排除或者纠正错误，保证系统能够正常运行，从而提高系统的可靠性和稳定性。

### 容量
容量是在一定时间内，系统能够处理的最大工作量或数据量，或指系统所能够承载的最大负载。系统容量与系统的硬件、软件、架构以及网络带宽等因素密切相关。在云上，还需要关注单个阿里云账号下的云服务配额，避免因触及云服务配额限制导致的业务故障。

## 变更设计原则

在企业的运维管理与运行过程中，就会有变更产生。变更是指添加、修改或删除任何可能对服务产生直接或间接影响的内容。当变更失败时可能会带来严重后果：业务中断、客户舆情等等一系列问题。为了降低变更带来的业务风险，需要遵循变更设计原则：可灰度、可监控、可回滚。

### 可灰度
可灰度，需要建立起完整的灰度发布机制，完善的灰度机制有助于变更失败时降低业务影响，提升用户体验。
灰度发布机制包含但不限于以下几点：灰度方式、灰度批次、间隔时间、灰度观测等。灰度发布需注意：

灰度发布方式：合理选择灰度发布方式，可按用户、按区域、按渠道等方式进行灰度，避免出现灰度过程中用户体验不一致的问题。

灰度间隔时间：合理设定灰度间隔时间，不宜过长。过长的灰度间隔时间可能导致下游应用出现数据不一致等问题。

灰度发布批次：建议先小范围的进行灰度验证，再逐步扩大灰度范围。

灰度观测指标：明确灰度期间的可观测指标，用于判断发布结果，避免造成连锁反应。

### 可回滚
大部分变更要做好应急恢复手段，最常用的技术手段就是回滚。

理论上回滚永远是最合适最有效的方法，当问题发生时，保证业务连续运行永远是第一要义。实际中可能存在其他解决方案，但后果无法预料，所以选择回滚是最好方式。

在发布时建议多版本小更新，避免因变更版本跨度较大，带来的系统依赖关系问题导致无法回滚。

### 可观测

在变更过程中，会影响到现有环境以及上下游业务，通过对业务、链路、资源等做到可观测，就能够第一时间发现问题。在观测过程中，关注业务指标（如下单成功率）和应用指标（如CPU、Load、异常数量等）。当指标较多时，优先关注高优先级的业务指标，业务指标能够最直观反映当前系统状况，当业务指标发生变化时，往往应用指标也会有相应的变化。

变更前需准备好对应的检查清单。在变更期间，要做到持续观察监控数据，确定是否有负面影响或问题。在变更结束后，对变更前后的业务指标进行对比，没有问题后才结束变更。


## 应急响应机制

应急响应机制的关键点在于事件发生后，有标准的操作流程和动作。阿里巴巴在过去十几年的安全生产过程中，沉淀了一套故障应急响应机制，简称应急响应1-5-10。是指在1分钟内发现故障，5分钟内组织相关人员进行初步排查，10分钟内开展故障恢复和处理工作。企业在设计应急响应机制时，可以参考该方式明确响应期间的标准动作和流程，确保在事件发生时，相关干系人都能够明确自身职责和所需要采取的措施。

### 故障发现

故障一旦发生，越早发现故障，能够越早进行响应。建议通过以下途径实现故障的快速发现：

统一告警：在发现故障后，需要将相关信息及时告知相关人员，包括系统管理员、运维人员等。可以通过短信、邮件、钉钉等方式进行告警，确保所有相关人员第一时间得知故障情况，以便快速组织应急响应。

监控大屏：监控大屏是指将所有系统的运行情况以图形化的方式展示在屏幕上，以便实时监控系统健康状况。在发生故障时，监控大屏可以快速反应故障情况，并提供相关数据，为故障排查及处理提供依据。

风险预测：风险预测是指在发生故障前，通过数据分析、机器学习等方式，预测系统的风险情况，提前进行预防和处理。在故障应急响应中，风险预测可以作为重要参考，帮助快速识别问题的根本原因，提高故障处理效率和精度

### 故障响应

在发现故障后，需要快速定位问题，通常有以下做法：

组织协调：故障发生后，需要迅速组织相关人员进行应急响应。组织协调包括设置指挥中心、确定应急响应流程、分配任务等。这些工作的目的是提高应急响应的效率和准确性，让每个人都清楚自己的任务和责任，避免出现混乱和误操作。

告警关联分析：在故障发生时，系统会自动产生告警信息。为了更好地定位故障原因，需要对各种告警信息进行关联分析。这样可以快速确定故障的范围和影响，并且能够帮助排查故障的根本原因。告警关联分析可以使用各种工具和算法，如事件关联分析、机器学习等。

知识图谱：知识图谱是指通过将各种数据和知识进行关联和组织，建立一种知识库或知识图谱，以便在故障发生时快速定位和解决问题。在应急响应中，知识图谱可以指导故障排查和处理工作，提高效率和准确性。知识图谱可以使用各种工具和技术，如自然语言处理、图数据库等。

### 故障恢复
定位故障原因后，按照应急预案快速恢复业务，并在事后进行复盘总结。

预案执行：在故障响应的过程中，需要按照事先制定的应急预案进行执行。应急预案包括了应急响应流程、各个岗位的职责、处理流程等。预案执行能够保证故障恢复和处理的规范化和标准化。

故障自愈：故障自愈是指系统自动检测到故障并采取自动恢复措施。故障自愈技术可以帮助故障恢复和处理更加快速和准确。例如，利用容器技术，系统可以自动迁移容器来解决故障。

故障复盘：故障复盘是指对故障进行分析和总结，以便更好地避免故障的再次发生。在故障复盘过程中，需要对故障的起因、影响、处理过程等进行详细的记录和分析，并制定相关的措施。故障复盘也是一种学习和提高的过程，能够不断完善系统和提高团队的应急响应能力。

## 演练常态化

故障演练提供了一种端到端的测试理念与工具框架，本质是通过主动引入故障来充分验证软件质量的脆弱性。从提前发现系统风险、提升测试质量、完善风险预案、加强监控告警、提升故障应急效率等方面做到故障发生前有效预防，故障发生时及时应对，故障恢复后回归验证。基于故障本身打造分布式系统韧性，持续提升软件质量，增强团队对软件生产运行的信心。故障演练可分为方案验证的容灾演练、稳定性验收的红蓝攻防，以及故障应急验证的突袭演练。

### 容灾演练

容灾演练是通过模拟实例、机房或地域级故障，判断系统服务的逃逸能力，验证系统的容灾能力以及面对灾难时的应对能力。容灾演练可以帮助企业更好的验证RPO、RTO指标，及时发现和解决相关问题，提高系统的可用性和可靠性。



### 红蓝攻防
红蓝攻防是在想定情况诱导下进行的作战指挥和行动演练，是部队在完成理论学习和基础训练之后实施的，近似实战的综合性训练，是军事训练的高级阶段。演习通常分为红军，蓝军，多以红军守，蓝军进攻为主。

红蓝攻防不仅能够用于安全演练，在稳定性演练中同样适用。在稳定性攻防中，蓝军从第三方角度发掘各类脆弱点，并向业务所依赖的各种软硬件注入故障，不断验证业务系统的可靠性。而红军则需要按照预先定义的故障响应和应急流程进行处置。在演练结束后，建议针对故障中的发现、响应、恢复三个阶段的时长和操作内容进行复盘，并梳理改进点进行优化，提升业务系统的稳定性。

### 突袭演练
突袭演练是一种手段以及目标对红军不透明的组织形式。通过突袭演练可以全面检验技术团队在面对突发故障时的应急和恢复能力，提升人员的安全意识。在突袭演练中，红蓝双方是纯对抗的关系，因此对红蓝双方提出了更高的要求，蓝军不仅需要了解目标系统的薄弱点，更需要了解目标系统的业务，红军不仅仅需要修复故障，还需要快速的发现故障和有效的应急协同。相比较计划演练，突袭演练涉及到的人员，场景，流程也会更加复杂，同时不但确保演练计划的私密性，还需要充分评估在红军未及时处理故障时的影响面控制。


# 高可用架构设计

## 容灾

容灾，就是在灾难发生时，在保证生产系统的数据尽量少丢失的情况下，保持生存系统的业务不间断地运行。异地多活、同城双活都属于容灾的范畴。

容灾需要具备较为完善的数据保护与灾难恢复功能，保证生产中心在不能正常工作时数据的完整性及业务的连续性，并在最短时间内由灾备中心接替，恢复业务系统的正常运行，将损失降到最小。


### 网络容灾

网络是数字世界的基础设施，没有网络的联通，所有信息都无法交互，因此网络架构的设计在应用系统中至关重要，特别是针对网络架构的高可用及容灾能力的设计，是业务在异常发生时，实现快速恢复、降低业务损失的关键。

#### 云上网络规划设计

预留
  - 预留IP地址
  - 


   region 
     - vpc
     - vpc
       - 交换机
       - 交换机
         - 关注剩余IP 地址数
  - 规划不同的region, 可用区及业务系统的IP地址空间
  - 在单个Region中，根据业务需求规划不同的VPC，各VPC使用独立的IP地址空间；
  - 在单个VPC中，根据业务需求规划交换机的可用区、IP地址空间；
  - 部分云服务可能短时间占用较多IP地址，可考虑针对性规划交换机避免IP地址资源不足。


#### 云上网络互联方案设计

大型企业一般都会有多个部门，每个部门又由多个团队组成，例如开发、测试、运维等。不同部门和团队使用云产品时，一般会使用多个VPC把业务隔离，不同的VPC承载不同部门或团队的业务。但不同团队和部门间在特定场景下也需要互相访问双方的服务，这时就需要实现不同VPC间的互通。


实现不同VPC之间的互通在阿里云上有两个主要方式：VPC对等连接及云企业网。

- 使用VPC对等连接两两互通：两两VPC之间需要互通的都需要配置对应的对等连接，在VPC数量较多的场景下，需要建立较多的对等连接，对网络管理复杂度有比较高的挑战

- 使用云企业网实现fullmesh全互通：所有需要互通的实例，例如VPC/VBR/VPN等，都连接到云企业网CEN，云企业网CEN就像一个Hub一样连接所有实例，任意一个VPC无论想与哪个VPC互通，都先经过CEN进行转发路由，这样降低了网络配置的复杂度。而且云企业网上可以配置丰富的路由策略，限速规则等功能，可以更好的满足大型企业的组网需求。
 

#### 互联网出口设计

- 避免不必要的公网暴露

- 云服务器ECS使用固定公网IP或者弹性公网IP的时候，通过安全组限制端口暴露面；

- 用网络云服务（如负载均衡SLB、公网NAT网关）为云服务ECS提供公网访问入口，而非直接在云服务器ECS上使用公网IP。

- 合理使用公网NAT网关实现云上公网访问

- 在安全访问较严格的场景中，使用主机粒度SNAT规则而非交换机粒度SNAT规则；

- 同一SNAT规则中各EIP带宽上限应保持一致；

- 根据业务需求使用不同的EIP配置不同的SNAT规则；

- 注意SNAT规则中EIP数目所能提供的并发连接数上限是否满足业务需求。

- 合理使用共享带宽提升云上公网访问能力

- 建议不同流量模型的业务使用不同的共享带宽实例，以便于配置不同的计费方式，降低业务成本；

- 建议为对公网带宽有资源隔离需求的业务配置单独的共享带宽实例。

#### 混合云互通高可用设计

随着企业逐步将新增业务、对外业务系统部署至云上，一些原有自建IDC机房的企业就需要打通云上和IDC以组成混合云。同时部分企业为了进一步提升业务高可用，也会使用多家云厂商的资源，以实现单家云厂商故障时，业务的快速逃逸，因此不同云厂商之间的往来互通也是混合云组网的必要条件。

实现混合云组网建设应满足以下原则：

- 链路冗余性：在混合云组网中需要至少两条线路进行冗余或者主备负载，当一条链路异常的时候可以切换到另外一条线路。实现链路冗余大体可以分为以下几类：

  - 双专线冗余：通过两条专线与IDC/其它云互通，其中一条链路中断可以快速切换到另外一条线路，需要注意在进行专线接入的时候尽可能选择两个不同的专线接入点提升高可用。如果为了满足业务对延迟等需求，必须选择相同接入点，也必须保证两条专线在两个不同的接入设备上，这样即使有一台设备故障导致其中一条线路异常时，也可以保证另外一条线路正常运转。

  - 专线/VPN主备：在物理专线、IPSec-VPN连接、BGP动态路由协议均正常运行的情况下，VPC实例可以通过物理专线和IPSec-VPN连接同时学习到本地IDC的网段，本地IDC也可以通过物理专线和IPSec-VPN连接同时学习到VPC实例的路由。系统默认通过物理专线学习到的路由的优先级高于通过IPSec-VPN连接学习到的路由，因此VPC实例和本地IDC之间的流量默认通过物理专线传输。当物理专线异常时，系统会自动撤销通过物理专线学习到的路由，通过IPSec-VPN连接学习到的路由会自动生效，VPC实例和本地IDC之间的流量会通过IPSec-VPN连接进行传输；当物理专线恢复后，VPC实例和本地IDC之间的流量会重新通过物理专线进行传输，IPSec-VPN连接会重新成为备用链路。此方案相比双专线冗余方案可节约成本，因IPSec-VPN成本较专线更低。但IPSec-VPN可承载流量上限一般不超过1Gbps，对于流量较小的业务可以采用此方案。

  - VPN冗余：如果本地数据中心拥有多个本地网关设备（本地网关设备上均拥有公网IP地址），用户可以使用其中的2个本地网关设备分别与阿里云专有网络VPC（Virtual Private Cloud）建立IPSec-VPN连接，每个IPSec-VPN连接关联不同的VPN网关，实现本地数据中心与VPC之间链路的高可用，同时实现流量的负载分担。本地数据中心可以分别通过两个VPN网关学习到VPC的路由，本地数据中心去往VPC的流量可以同时通过这两个VPN网关进行传输，实现流量的负载分担。在其中一个VPN网关不可用时，当前VPN网关下的流量默认会自动通过另一个VPN网关进行传输，实现链路的高可用。VPC可以分别通过两个VPN网关学习到本地数据中心的路由，但是VPC默认仅通过一个VPN网关（系统优先选择实例ID较小的VPN网关）转发从VPC去往本地数据中心的流量，在当前VPN网关不可用后，才会通过另一个VPN网关转发流量（系统自动切换），因此VPC去往本地数据中心的流量可以通过两个VPN网关实现链路的高可用，但不支持负载分担。

- 带宽容量设计：在选择混合云互通方案的时候，一定要考虑互通的带宽容量需求，不同的带宽对方案的选型至关重要，例如大型企业对混合云流量需求较大，可达到数Gbps或者上百Gbps，此时就需要使用冗余专线的方案，而且需要确保冗余专线的水位保持在50%以下，达到或者接近50%就需要及时扩容，因为两条专线都在50%的水位运行，当有一条线路异常的时候，流量就会全部负载到另外一条线路，导致另外一条线路水位达到100%无法承接所有流量从而影响业务。

- 链路快速倒换：如果企业已经实现了冗余线路打通IDC，也需要通过技术方案实现异常时的快速切换。



## 流量容灾调度

随着互联网的快速发展，为保证业务的持续高可用，同城多活、异地多活已成为各企业的不二之选。服务设置多中心，中心内部多地址负载，是多数企业采用的常规做法。这种情况下，如何对流量进行有效控制以达到最佳的用户访问效率、部分地域业务异常如何快速业务容灾到其他地域，业务具备全球流量调度以及容灾能力变得尤为重要，列举其中几个典型场景。 

（1） 业务需要实现用户就近访问服务中心减少网络耗时。 
（2） 服务中心多个IP地址如何实现负载均摊或者权重轮询，且保证整体负载的稳定性。 
（3） 服务中心某IP地址故障后，快速发现并实现隔离，地址恢复后自动添加至解析列表，完全无需人为干预。 
（4） 当某中心故障发生时，快速切流到其他中心，减少中断时间。 

阿里云全局流量管理（Global Traffic Manager，简称GTM）可以有效解决上面几个问题，它基于阿里云DNS入口调度和分布式云监控，旨在帮助企业实现用户访问应用服务的就近接入、高并发负载均摊、应用服务的健康检查，并能够根据健康检查结果实现故障隔离或流量切换，方便企业灵活快速的构建同城多活和异地容灾服务。

与传统DNS解析相比，GTM主要具备如下特点：

地址池： 传统DNS解析到单个地址，而GTM则引入地址池概念。如图1中的PoolA/B/C所示，一个地址池代表一组提供相同应用服务，即具备相同运营商或地区属性的IP地址或域名地址。通过地址池可对应用服务的IP地址进行统一管理。实现将终端用户访问解析到应用服务地址池，既可实现高负载情况下的流量均摊，又可实现自定义流量分配。同时当地址池整体不可用时，可以做备份切换。

健康检查： 依托于云监控强大的分布式监控功能，GTM新增了HealthCheck模块，如GTM原理图所示，从多个地区对地址池内的多个应用服务IP地址发起健康探测，目前已支持http/https、tcp、ping三种方式。当地址池中地址发生故障时HealthCheck模块会准确的检测到异常情况并与DNS交互，摘除故障地址。并当故障地址恢复时，自动恢复至解析返回列表。

访问策略： 访问策略旨在解决根据请求来源和地址池健康情况进行地址池切换的问题。既能做到地址池维度智能解析，又可实现故障自动切换功能。当地址池整体出现故障时，GTM会根据用户自定义策略进行地址池分钟级切换，并当地址池恢复时切回。


![](https://ieasydevops.github.io/assets/images/2023/1012/gtm.jpeg)


异地容灾

下面以异地双活为例介绍如何借助GTM实现快速容灾切换。如下图所示，某服务的用户主要分为海外用户和国内用户，后端服务采用一套部署方案。通过GTM对不同地区用户请求进行智能调度，将用户访请求流量路由至不同的接入服务点，即海外用户访问新加坡中心（Singapore），国内用户访问杭州中心（CN-Hangzhou）。当某站点发生故障灾难时，各接入站点自建互相备份，最终实现业务的高可用。

![](https://ieasydevops.github.io/assets/images/2023/1012/ansync_loc.png)

1. 全局配置：基础配置，主要配置负载均衡策略、全局TTL、报警通知组等相关信息。

2. 地址池配置：新建地址池Singapore和CN-Hangzhou。每个地址池中均配置该区域下多个服务IP，以及最小可用地址数量。当地址池存活地址数小于该地址池数量时，则地址池视为不可用。此外，根据全局配置中负载均衡策略自动实现流量分配。

3. 开启健康检查：即对地址池中的IP地址配置健康检查，开启后可实现实时监测地址的可用性状态。根据地址的可用性进行故障自动隔离，并通知相应报警组。当地址恢复后，自动添加至解析列表。此外，当地址池整体出现问题时，触发默认地址池与备用地址池之间自动切换。能达到5分钟内，90%流量的切换速度。

4. 访问策略配置：根据用户的请求来源设置最终用户访问哪一个地址池。如图所示，海外用户希望访问Singapore地址池，则需设置相应访问策略，请求来源设置海外地区，默认地址池为Singapore，备用地址池设置CN-Hangzhou。则正常请求下，则海外用户访问Singapore中心，发生故障后会快速切换至CN-Hangzhou中心。

5. CNAME接入配置：需要将用户访问的主域名CNAME至全局流量管理的实例域名，才能最终实现对应用服务进行容灾、智能接入。即将图中的www.cloud-example.com CNAME到我们提供的接入域名。

配置完成后，我们将根据健康配置实时探测地址池中地址，当地址发生报警时，则根据下图的流程进行判断，实现容灾切换，以上图中IP地址A报警为例。由此可见，当默认地址池（Singapore）地址池可用时，则解析列表摘除地址A，当默认地址池整体不可用时则切换备用地址池（CN-Hangzhou），切换过程自动完成，并缩小时间至分钟级。从而有效保证异地容灾的切换效率。


### 容灾预案

此外，全局流量管理新增的容灾预案功能可以帮助用户实现日常容灾演练，或在应用服务出现故障时实现快速切换流量。容灾预案支持批量地址池故障模拟及回滚，帮用户验证切换策略是否符合预期。





******************************************************************************

# 应用容灾

“应用多活”是“应用容灾”技术的一种高级形态，指在同城或异地机房建立一套与本地生产系统部分或全部对应的生产系统，所有机房内的应用同时对外提供服务。当灾难发生时，多活系统可以分钟级内实现业务流量切换，用户甚至感受不到灾难发生。“同城多活架构”和“异地多活架构”（代号“单元化”）都是典型的应用多活实现技术。

![](https://ieasydevops.github.io/assets/images/2023/1012/muti_alive.png)


## 应用多活的优势
- 分钟级RTO：恢复时间快，阿里内部生产级别恢复时间平均在30s以内，外部客户生产系统恢复时间平均在 1 分钟。

- 资源充分利用：资源不存在闲置的问题，多机房多资源充分利用，避免资源浪费。

- 切换成功率高：依托于成熟的多活技术架构和可视化运维平台，相较于现有容灾架构，切换成功率高，阿里内部年切流数千次的成功率高达 99.9%以上。

- 流量精准控制：应用多活支持流量自顶到底封闭，依托精准引流能力将特定业务流量打入对应机房，企业可基于此优势能力孵化全域灰度、重点流量保障等特性。


## 应用多活的设计标准

- 业务流量多活（BFA，BusinessFlowActive）：应用多活的最终呈现是业务，多活容灾系统具备按照业务特征进行生产流量的精细化调配。

- 同城多活（LRA，LocalRegionActive）：应用是分布式系统的最小服务集合，当主中心出现问题进入容灾态时，要具备全局或局部应用的多活切换能力。

- 异地多活（UDA，UltraDistanceActive）：在超远距离（机房间距超过300公里）时，业务系统仍具备较好的访问性能。进入容灾态时，RTO、RPO 在分钟级。

- 混合云多活（HCA，HybridCloudActive）：向上对业务屏蔽容灾细节，提供统一的多活编程范式。 向下对云平台技术保持兼容，支持公有云、私有云、托管私有云、边缘计算节点等不同部署模式的多活场景。

![](https://ieasydevops.github.io/assets/images/2023/1012/bfa.png)


# 应用多活的典型架构

## 同城场景的应用多活

同城应用多活，顾名思义就是分布在同城多个机房内的应用同时对外提供服务。同城机房物理距离较小 (物理距离小于 100 公里）。同城场景下多机房的网络、服务互通，某机房局部故障会影响到全局，爆炸半径不可控。应用多活架构的难点，在于机房之间的流量路由和隔离。当某机房出现故障，可以做到机房级的快速切换。更精细化的场景，如果是某中心内某应用的故障，还需要做到应用级的切换。

![](https://ieasydevops.github.io/assets/images/2023/1012/lra.png)

同城应用多活对应用系统的代码侵入较小，基于灵活的流量调度和单元格间的流量路由，能做到故障场景下的业务快速恢复，实现业务恢复与故障恢复的解耦。



## 异地场景的应用多活

同城近距离的容灾建设难以抵御地域级别的灾难，参考银行业的容灾标准，灾备中心建设都要求满足“三不原则”（即灾备中心与生产中心不应设立在同一地震带，同一江河流域，同一电网），因此异地灾备中心一般距离生产中心 300 公里以上。

异地应用多活，顾名思义就是分布在异地多个机房内的应用同时对外提供服务。在异地超远距离的场景下建设应用多活，最大的挑战在于超远距离带来的网络延迟。由于网络延迟大，云服务很难跨地域的以单集群的模式提供服务，而多集群模式下会带来数据一致性的复杂度。

为了解决单集群无法突破物理距离限制的问题，阿里提出了“单元化”方案。核心思路是对数据进行分片，通过自上而下的流量路由，让特定分片的数据到特定中心完成读写，以此解决数据一致性的问题，并在此基础上解决了业务的容灾和水平扩展问题。这个可以水平扩展的逻辑中心称为“单元（Unit）”。

单元分为两种类型，中心单元与普通单元。单元内部署的业务分为三种类型，全局业务、核心业务、共享业务。中心单元只有一个，部署全局业务、核心业务、共享业务。普通单元部署核心业务、共享业务，普通单元具备水平的扩展能力，可以任意复制。

![](https://ieasydevops.github.io/assets/images/2023/1012/cell.png)


问题： 按照何种规则进行单元化的拆分？ 针对公司的业务，怎么进行业务切分？清单？


## 混合云场景的应用多活

混合云融合了公有云、私有云、托管私有云、边缘计算节点等不同部署模式，面向企业云上基础架构、中间件、开发全生命周期和/或应用平台的各种能力需求，为云上开发、构建、运维、运营、管控等各种技术与业务实践提供支持。IDC 报告中显示 2021 年有 14% 的客户会单独选择公共云，86% 企业采用多云混合云架构。

混合云应用多活，顾名思义就是分布在混合云环境的应用均对外提供服务。混合云应用多活架构是在多云和异构场景衍生的容灾架构方案，将业务恢复和云基础架构、云服务解耦。混合云多活管理产品对开 发者和上层用户屏蔽混合云容灾的复杂度，提供一致的开发、运维、运营体验。

混合云应用多活，最大的挑战在于多云独立和多云异构，做到多云集成和数据互通。多云集成，即集成多云的账号、权限、资源、数据，在此基础上构建统一的多云操作界面。数据互通，即多云的基础架构、异构的中间件体系，需要做到互相发现、互相同步，在此基础上实现数据的容灾。

为了实现多云集成与数据互通，混合云多活管理需要有多云适配来屏蔽底层的差异，主要依靠三大核心功能：

- 云服务接口适配，对下通过插件化支持多云适配，对上提供统一的云服务接口。

- 数据模型适配，对云的账号、权限、资源、数据进行抽象，屏蔽多云的数据差异。

- 统一容灾接口，提供标准化的容灾定义和接口，利于异构云异构技术栈的快速接入。

![](https://ieasydevops.github.io/assets/images/2023/1012/ansync_loc.png)




# 应用多活的技术方案

应用多活的技术方案一般分为三部分，分别为应用层、数据层和云平台。三部分组件遵循应用多活的设计标准，支撑应用构建应用多活架构能力。应用层是业务应用流量主经的链路，基本构成可分为三部分：

- 接入网关：接入网关作为业务流量打入机房的第一跳，负责应用多活入口流量的识别和分发，具备机房路由和应用路由两个核心能力。

- 微服务：业务流量在机房内部和跨机房的同步调用方式，一般有 Consumer、Provider、注册中心等角色，具备流量路由、流量保护、故障隔离三个核心能力。

- 消息：业务流量在机房内部和跨机房的异步调用方式，基于消息削峰填谷，一般有 Producer、 Consumer、Broker 等角色。

数据层涵盖业务应用数据读写、数据存储和数据同步，其具备流量路由、数据一致性保护、数据同步三个核心能力。
云平台是支撑业务应用运行的核心基石，基本构成覆盖单云、单机房、多云、混合云等形态。

![](https://ieasydevops.github.io/assets/images/2023/1012/cloud_plat.png)






公司当前现状分析
    公司当前的架构为混合云的架构，可以借助云计算平台服务的能力，解决一部分系统稳定性的，可扩展性的问题。单在当前业务在多个云的资源生命周期管理，流量调度层尚缺乏对应的工具系统支撑

 
改进的思路


运营方案

技术方案

系统的度量指标

总结和反思




# 名次解释

RTO：（RecoveryTime Object）是指灾难发生后，从IT系统宕机导致业务停顿之刻开始，到IT系统恢复至可以支持各部门运作，业务恢复运营之时，此两点之间的时间段称为RTO。